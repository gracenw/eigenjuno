{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries and navigate to directory\n",
    "%cd '/home/uzumochi/training_set_small'\n",
    "import cv2\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy import genfromtxt\n",
    "import os\n",
    "from sklearn.svm import SVC, SVR, LinearSVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pca with contrasted data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tag system:  \n",
    "0 - no storms  \n",
    "1 - small storms  \n",
    "2 - big storms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in contrasted data and tags, set loop parameters (1)\n",
    "vec_size = 256 * 256 * 3;\n",
    "data = np.empty((186, vec_size))\n",
    "for i in range(1, 187):\n",
    "    img = mpimg.imread(str(i) + '.png')\n",
    "    img = img[:, :, :3]\n",
    "    img_1d = np.reshape(img, vec_size)\n",
    "    data[i - 1, :] = img_1d;\n",
    "tags = genfromtxt('/home/uzumochi/tags.csv', delimiter=',')\n",
    "for i in range(186):\n",
    "    if tags[i] == 2:\n",
    "        tags[i] = 1\n",
    "iterations = 5\n",
    "test_size = 40\n",
    "num_tests = 10\n",
    "accuracy = np.zeros(num_tests)\n",
    "total_predictions = iterations * test_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(iterations):\n",
    "    # split data into training and test sets (2)\n",
    "    x_train, x_test, y_train, y_test = train_test_split(data, tags, test_size = test_size)\n",
    "\n",
    "    # perform original transform again for classification purposes (3)\n",
    "    pca_x = PCA().fit(x_train)\n",
    "    x_train_pca = pca_x.transform(x_train)\n",
    "\n",
    "    # compute eigenfaces (4)\n",
    "    eigenfaces = pca_x.components_.reshape((x_train.shape[0], 256, 256, 3))\n",
    "\n",
    "    # apply pca transform to x_test (5)\n",
    "    x_test_pca = pca_x.transform(x_test)\n",
    "    classifier_linsvc = LinearSVC().fit(x_train_pca, y_train)\n",
    "    classifier_svc = SVC().fit(x_train_pca, y_train)\n",
    "    classifier_mlp = MLPClassifier(activation='logistic').fit(x_train_pca, y_train)\n",
    "    classifier_nearestneighbor = KNeighborsClassifier(weights = 'distance').fit(x_train_pca, y_train)\n",
    "    classifier_decisiontree = DecisionTreeClassifier().fit(x_train_pca, y_train)\n",
    "    classifier_randomforest = RandomForestClassifier().fit(x_train_pca, y_train)\n",
    "    classifier_adaboost = AdaBoostClassifier().fit(x_train_pca, y_train)\n",
    "    classifier_naivebayes = GaussianNB().fit(x_train_pca, y_train)\n",
    "    classifier_lda = LinearDiscriminantAnalysis().fit(x_train_pca, y_train)\n",
    "    classifier_qda = QuadraticDiscriminantAnalysis().fit(x_train_pca, y_train)\n",
    "    y_pred_LSVC = classifier_linsvc.predict(x_test_pca)\n",
    "    y_pred_SVC = classifier_svc.predict(x_test_pca)\n",
    "    y_pred_MLP = classifier_mlp.predict(x_test_pca)\n",
    "    y_pred_NN = classifier_nearestneighbor.predict(x_test_pca)\n",
    "    y_pred_DT = classifier_decisiontree.predict(x_test_pca)\n",
    "    y_pred_RF = classifier_randomforest.predict(x_test_pca)\n",
    "    y_pred_AB = classifier_adaboost.predict(x_test_pca)\n",
    "    y_pred_NB = classifier_naivebayes.predict(x_test_pca)\n",
    "    y_pred_LDA = classifier_lda.predict(x_test_pca)\n",
    "    y_pred_QDA = classifier_qda.predict(x_test_pca)\n",
    "    predictions = [y_pred_SVC, y_pred_LSVC, y_pred_MLP, y_pred_NN, y_pred_DT, y_pred_RF, y_pred_AB, y_pred_NB, y_pred_LDA, y_pred_QDA]\n",
    "\n",
    "    # log accuracy (6)\n",
    "    for i in range(num_tests):\n",
    "        for k in range(test_size):\n",
    "            if predictions[i][k] == y_test[k]:\n",
    "                accuracy[i] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print results from testing (7)\n",
    "accuracy = accuracy / total_predictions\n",
    "print('Support Vector Classifier: ' + str(\"{:.3f}\".format(accuracy[0])))\n",
    "print('Linear Support Vector Classifier: ' + str(\"{:.2f}\".format(accuracy[1])))\n",
    "print('Multilayer Perceptron Classifier: ' + str(\"{:.2f}\".format(accuracy[2])))\n",
    "print('K-Nearest Neighbor: ' + str(\"{:.2f}\".format(accuracy[3])))\n",
    "print('Decision Tree: ' + str(\"{:.2f}\".format(accuracy[4])))\n",
    "print('Random Forest: ' + str(\"{:.2f}\".format(accuracy[5])))\n",
    "print('Adaptive Boosting: ' + str(\"{:.2f}\".format(accuracy[6])))\n",
    "print('Gaussian Naive Bayes: ' + str(\"{:.2f}\".format(accuracy[7])))\n",
    "print('Linear Discriminant Analysis: ' + str(\"{:.2f}\".format(accuracy[8])))\n",
    "print('Quadratic Discriminant Analysis: ' + str(\"{:.2f}\".format(accuracy[9])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_data = PCA().fit(data)\n",
    "data_pca = pca_data.transform(data)\n",
    "eigenfaces = pca_data.components_.reshape((data.shape[0], 256, 256, 3))\n",
    "classifier_svc = SVC().fit(data_pca, tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# read in new data and predict\n",
    "%cd '/home/uzumochi/test_imgs'\n",
    "vec_size = 256 * 256 * 3\n",
    "test_predict = np.empty(64)\n",
    "# img = cv2.imread('1.png')\n",
    "# img = cv2.cvtColor(img, cv2.COLOR_BGR2LAB);\n",
    "# l, a, b = cv2.split(img);\n",
    "# clahe = cv2.createCLAHE(clipLimit = 3.0, tileGridSize = (8, 8));\n",
    "# img_l = clahe.apply(l);\n",
    "# img_l = cv2.merge((img_l, a, b));\n",
    "# final = cv2.cvtColor(img_l, cv2.COLOR_LAB2BGR);\n",
    "# final = cv2.cvtColor(final, cv2.COLOR_BGR2RGB);\n",
    "# img = cv2.resize(final, (2048, 2048), interpolation = cv2.INTER_NEAREST)\n",
    "# plt.imsave('/home/uzumochi/test_imgs/1_contrast.png', img)\n",
    "img = mpimg.imread('1_contrast.png')\n",
    "split_img = np.empty((64, vec_size))\n",
    "start_row = 0\n",
    "start_col = 0\n",
    "end_row = 256\n",
    "end_col = 256\n",
    "row_idx = np.array([])\n",
    "for i in range(64):\n",
    "    block = img[start_row : end_row, start_col : end_col]\n",
    "    block = block[:, :, :3]\n",
    "    if end_col != 2048:\n",
    "        start_col += 256\n",
    "        end_col += 256\n",
    "    else:\n",
    "        start_col = 0\n",
    "        end_col = 256\n",
    "        start_row += 256\n",
    "        end_row += 256\n",
    "    split_img[i, :] = np.reshape(block, vec_size)\n",
    "    if np.mean(split_img[i, :]) >= 0.35:\n",
    "        row_idx = np.append(row_idx, i)\n",
    "\n",
    "split_test_pca = pca_data.transform(split_img[row_idx.astype(int), :])\n",
    "# print(split_test_pca)\n",
    "plt.plot(pca_data.explained_variance_ratio_.cumsum());\n",
    "split_pred = classifier_svc.predict(split_test_pca)\n",
    "# print(split_pred)\n",
    "# for pred in split_pred:\n",
    "#     if pred != 0:\n",
    "#         cv2.rectangle(img, (x1, y1), (x2, y2), (255,0,0), 2)\n",
    "fig, axes = plt.subplots(8, 8, figsize = (18, 18));\n",
    "index = 0\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.imshow(split_img[i - 1, :].reshape(256, 256, 3))\n",
    "    if (i - 1) in row_idx:\n",
    "        ax.title.set_text(str(\"{:.2f}\".format(split_pred[index])))\n",
    "        index += 1\n",
    "    ax.axis('off')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -----------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## adjust images to uniform 400x400 size\n",
    "*only run me if uniform images are not already present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# navigate to directory and adjust data to uniform size\n",
    "%cd 'training_set_crop'\n",
    "for i in range(1,187):\n",
    "    img = mpimg.imread(str(i) + '.png')\n",
    "    img = img[:,:,:3]\n",
    "    img = cv2.resize(img, (400, 400), interpolation = cv2.INTER_NEAREST)\n",
    "    plt.imsave('/home/uzumochi/training_set_crop_uniform/' + str(i) + '.png', img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## contrast images and save\n",
    "*only run me if contrasted images are not already present# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# navigate to directory and contrast images using CLAHE\n",
    "%cd 'training_set_crop_uniform'\n",
    "for i in range(1,187):\n",
    "    img = cv2.imread(str(i) + '.png')\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2LAB);\n",
    "    l, a, b = cv2.split(img);\n",
    "    clahe = cv2.createCLAHE(clipLimit = 3.0, tileGridSize = (8, 8));\n",
    "    img_l = clahe.apply(l);\n",
    "    img_l = cv2.merge((img_l, a, b));\n",
    "    final = cv2.cvtColor(img_l, cv2.COLOR_LAB2BGR);\n",
    "    final = cv2.cvtColor(final, cv2.COLOR_BGR2RGB);\n",
    "    img = cv2.resize(final, (400, 400), interpolation = cv2.INTER_NEAREST)\n",
    "    plt.imsave('/home/uzumochi/training_set_crop_uniform_contrast/' + str(i) + '.png', img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pca with uncontrasted data\n",
    "*only keeping for archival purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in data\n",
    "vec_size = 400 * 400 * 3;\n",
    "train = np.empty((186, vec_size))\n",
    "for i in range(1, 187):\n",
    "    img = mpimg.imread(str(i) + '.png')\n",
    "    img = img[:, :, :3]\n",
    "    img_1d = np.reshape(img, vec_size)\n",
    "    train[i - 1, :] = img_1d * 255\n",
    "    \n",
    "# plot images\n",
    "fig, axes = plt.subplots(31, 6, figsize = (15, 50));\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.imshow(train[i - 1, :].reshape(400, 400, 3) / 255)\n",
    "    ax.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# calculate and plot pca\n",
    "pca = PCA().fit(train)\n",
    "plt.figure(figsize = (15, 5))\n",
    "plt.plot(pca.explained_variance_ratio_.cumsum());\n",
    "\n",
    "# transform data with pca\n",
    "data_pca = pca.transform(train)\n",
    "print(np.where(pca.explained_variance_ratio_.cumsum() > 0.95));\n",
    "\n",
    "# transform data with minimum required principal components\n",
    "pca = PCA(n_components = 6).fit(train)\n",
    "plt.figure(figsize = (15, 5))\n",
    "plt.plot(pca.explained_variance_ratio_.cumsum());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## random code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# visualize results\n",
    "fig, axes = plt.subplots(4, 4, figsize = (15, 15));\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.imshow(x_test[i - 1, :].reshape(256, 256, 3))\n",
    "    ax.title.set_text(str(int(y_test[i - 1])) + \" / \" + str(int(y_pred_SVC[i - 1])))\n",
    "    ax.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot contrasted images\n",
    "fig, axes = plt.subplots(31, 6, figsize = (15, 50));\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.imshow(data[i - 1 , :].reshape(256, 256, 3))\n",
    "    ax.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate and plot contrasted pca\n",
    "pca_x = PCA().fit(x_train)\n",
    "plt.figure(figsize = (15, 5))\n",
    "plt.plot(pca_x.explained_variance_ratio_.cumsum());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform data with contrasted pca\n",
    "x_train_pca = pca_x.transform(x_train)\n",
    "print(np.where(pca_x.explained_variance_ratio_.cumsum() > 0.95));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize first 5 pca components\n",
    "pca_x = PCA(n_components = 6).fit(x_train)\n",
    "plt.figure(figsize = (15, 5))\n",
    "plt.plot(pca_x.explained_variance_ratio_.cumsum());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform data with minimum required contrasted principal components\n",
    "pca_x = PCA(n_components = 75).fit(x_train)\n",
    "plt.figure(figsize = (15, 5))\n",
    "plt.plot(pca_x.explained_variance_ratio_.cumsum());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(eigenfaces.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot eigenfaces\n",
    "fig, axes = plt.subplots(93, 2, figsize = (4, 200));\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.imshow(abs(eigenfaces[i, :]) * 255);\n",
    "    ax.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform data to 2 dimensions\n",
    "x_pca = PCA(2).fit(x_train)\n",
    "x_train_pca = x_pca.transform(x_train)\n",
    "plt.scatter(x_train_pca[:, 0], x_train_pca[:, 1], edgecolor='none', alpha=0.5, cmap=plt.cm.get_cmap('rainbow', 2))\n",
    "plt.xlabel('component 1')\n",
    "plt.ylabel('component 2')\n",
    "plt.colorbar();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inverse transform data\n",
    "x_train_new = x_pca.inverse_transform(x_train_pca)\n",
    "plt.scatter(x_train[:, 0], x_train[:, 1], alpha=0.2)\n",
    "plt.scatter(x_train_new[:, 0], x_train_new[:, 1], alpha=0.8)\n",
    "plt.axis('equal');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in new data and predict\n",
    "%cd '/home/uzumochi/test_imgs'\n",
    "img = mpimg.imread(str(1) + '.png')\n",
    "img = img[:, :, :3]\n",
    "print(img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2LAB);\n",
    "l, a, b = cv2.split(img);\n",
    "clahe = cv2.createCLAHE(clipLimit = 3.0, tileGridSize = (8, 8));\n",
    "img_l = clahe.apply(l);\n",
    "img_l = cv2.merge((img_l, a, b));\n",
    "final = cv2.cvtColor(img_l, cv2.COLOR_LAB2BGR);\n",
    "final = cv2.cvtColor(final, cv2.COLOR_BGR2RGB);\n",
    "img = cv2.resize(final, (400, 400), interpolation = cv2.INTER_NEAREST)\n",
    "img_1d = np.reshape(img, vec_size)\n",
    "test_predict = classifier_svc.predict(img_1d)\n",
    "print(test_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('LinearSVC')\n",
    "# print(classification_report(y_test, y_pred_LSVC, target_names = ['No storms', 'Storms']))\n",
    "# print('\\nSVC')\n",
    "# print(classification_report(y_test, y_pred_SVC))\n",
    "# print('\\nMLPClassifier')\n",
    "# print(classification_report(y_test, y_pred_MLP))\n",
    "# print('\\nNearest Neighbor')\n",
    "# print(classification_report(y_test, y_pred_NN))\n",
    "# print('\\nDecision Tree')\n",
    "# print(classification_report(y_test, y_pred_DT))\n",
    "# print('\\nRandom Forest')\n",
    "# print(classification_report(y_test, y_pred_RF))\n",
    "# print('\\nAda Boost')\n",
    "# print(classification_report(y_test, y_pred_AB))\n",
    "# print('\\nNaive Bayes')\n",
    "# print(classification_report(y_test, y_pred_NB))\n",
    "# print('\\nLDA')\n",
    "# print(classification_report(y_test, y_pred_LDA))\n",
    "# print('\\nQDA')\n",
    "# print(classification_report(y_test, y_pred_QDA))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new = np.empty((114, vec_size))\n",
    "tags_new = np.array([])\n",
    "index = 0\n",
    "for i in range(186):\n",
    "    if tags[i] != 1:\n",
    "        tags_new = np.append(tags_new, tags[i])\n",
    "        data_new[index] = data[i, :]\n",
    "        index += 1\n",
    "data = data_new\n",
    "tags = tags_new"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
