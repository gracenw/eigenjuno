{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries and navigate to directory\n",
    "import cv2, sys, os, random\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy import genfromtxt\n",
    "from sklearn.svm import SVC, SVR, LinearSVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import classification_report\n",
    "# np.set_printoptions(threshold=sys.maxsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pca with contrasted data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tag system:  \n",
    "0 - no storms  \n",
    "1 - storms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in contrasted data and tags, set loop parameters (1)\n",
    "%cd '/home/uzumochi/eigenjuno/data/train/contrast_256'\n",
    "vec_size = 256 * 256 * 3;\n",
    "data = np.empty((78 * 2, vec_size))\n",
    "# need to make sure the dataset class distribution is even - will not correctly identify no storms otherwise\n",
    "storm_indices = []\n",
    "no_storm_indices = []\n",
    "tags = genfromtxt('/home/uzumochi/eigenjuno/data/train/tags.csv', delimiter=',')\n",
    "for t in range(len(tags)):\n",
    "    if tags[t] == 1:\n",
    "        storm_list.append(t)\n",
    "    else:\n",
    "        no_storm_imgs.append(t)\n",
    "storm_imgs = random.sample(storm_list, 78)\n",
    "selected_imgs = storm_imgs + no_storm_imgs\n",
    "curr = 0\n",
    "for i in range(1, 281):\n",
    "    if i in selected_imgs:\n",
    "        img = mpimg.imread(str(i) + '.png')\n",
    "        img = img[:, :, :3]\n",
    "        img_1d = np.reshape(img, vec_size)\n",
    "        data[curr, :] = img_1d;\n",
    "        curr += 1\n",
    "tags = [tags[i] for i in selected_imgs]\n",
    "iterations = 5\n",
    "test_size = 40\n",
    "num_tests = 1\n",
    "accuracy = np.zeros(num_tests)\n",
    "total_predictions = iterations * test_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(iterations):\n",
    "    # split data into training and test sets\n",
    "    x_train, x_test, y_train, y_test = train_test_split(data, tags, test_size = test_size)\n",
    "    print(x_test.shape)\n",
    "\n",
    "    # perform original transform again for classification purposes\n",
    "    pca_x = PCA().fit(x_train)\n",
    "    x_train_pca = pca_x.transform(x_train)\n",
    "\n",
    "    # compute eigenfaces\n",
    "    eigenfaces = pca_x.components_.reshape((x_train.shape[0], 256, 256, 3))\n",
    "\n",
    "    # apply pca transform to x_test\n",
    "    x_test_pca = pca_x.transform(x_test)\n",
    "    classifier_linsvc = LinearSVC().fit(x_train_pca, y_train)\n",
    "    classifier_svc = SVC().fit(x_train_pca, y_train)\n",
    "    classifier_mlp = MLPClassifier(activation='logistic').fit(x_train_pca, y_train)\n",
    "    classifier_nearestneighbor = KNeighborsClassifier(weights = 'distance').fit(x_train_pca, y_train)\n",
    "    classifier_decisiontree = DecisionTreeClassifier().fit(x_train_pca, y_train)\n",
    "    classifier_randomforest = RandomForestClassifier().fit(x_train_pca, y_train)\n",
    "    classifier_adaboost = AdaBoostClassifier().fit(x_train_pca, y_train)\n",
    "    classifier_naivebayes = GaussianNB().fit(x_train_pca, y_train)\n",
    "    classifier_lda = LinearDiscriminantAnalysis().fit(x_train_pca, y_train)\n",
    "    classifier_qda = QuadraticDiscriminantAnalysis().fit(x_train_pca, y_train)\n",
    "    y_pred_LSVC = classifier_linsvc.predict(x_test_pca)\n",
    "    y_pred_SVC = classifier_svc.predict(x_test_pca)\n",
    "    y_pred_MLP = classifier_mlp.predict(x_test_pca)\n",
    "    y_pred_NN = classifier_nearestneighbor.predict(x_test_pca)\n",
    "    y_pred_DT = classifier_decisiontree.predict(x_test_pca)\n",
    "    y_pred_RF = classifier_randomforest.predict(x_test_pca)\n",
    "    y_pred_AB = classifier_adaboost.predict(x_test_pca)\n",
    "    y_pred_NB = classifier_naivebayes.predict(x_test_pca)\n",
    "    y_pred_LDA = classifier_lda.predict(x_test_pca)\n",
    "    y_pred_QDA = classifier_qda.predict(x_test_pca)\n",
    "    predictions = [y_pred_SVC, y_pred_LSVC, y_pred_MLP, y_pred_NN, y_pred_DT, \n",
    "                   y_pred_RF, y_pred_AB, y_pred_NB, y_pred_LDA, y_pred_QDA]\n",
    "\n",
    "    # log accuracy\n",
    "    for i in range(num_tests):\n",
    "        for k in range(test_size):\n",
    "            if predictions[i][k] == y_test[k]:\n",
    "                accuracy += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print results from testing (7)\n",
    "accuracy = accuracy / total_predictions\n",
    "print('Support Vector Classifier: ' + str(\"{:.3f}\".format(accuracy[0])))\n",
    "print('Linear Support Vector Classifier: ' + str(\"{:.2f}\".format(accuracy[1])))\n",
    "print('Multilayer Perceptron Classifier: ' + str(\"{:.2f}\".format(accuracy[2])))\n",
    "print('K-Nearest Neighbor: ' + str(\"{:.2f}\".format(accuracy[3])))\n",
    "print('Decision Tree: ' + str(\"{:.2f}\".format(accuracy[4])))\n",
    "print('Random Forest: ' + str(\"{:.2f}\".format(accuracy[5])))\n",
    "print('Adaptive Boosting: ' + str(\"{:.2f}\".format(accuracy[6])))\n",
    "print('Gaussian Naive Bayes: ' + str(\"{:.2f}\".format(accuracy[7])))\n",
    "print('Linear Discriminant Analysis: ' + str(\"{:.2f}\".format(accuracy[8])))\n",
    "print('Quadratic Discriminant Analysis: ' + str(\"{:.2f}\".format(accuracy[9])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # for use with block below train with full dataset and classify with SVC\n",
    "pca_of_data = PCA().fit(data)\n",
    "transform_data = pca_of_data.transform(data)\n",
    "# eigenfaces = pca_of_data.components_.reshape((data.shape[0], 256, 256, 3))\n",
    "classifier_svc = SVC().fit(transform_data, tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=5)\n",
    "proj = pca.fit_transform(data)\n",
    "plt.scatter(proj[:, 0], proj[:, 1]) \n",
    "plt.colorbar() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in new data and predict -- UNDER CONSTRUCTION\n",
    "%cd '/home/uzumochi/eigenjuno/data/test'\n",
    "%matplotlib inline\n",
    "vec_size = 256 * 256 * 3\n",
    "test_predict = np.empty(64)\n",
    "# img = cv2.imread('test3.png')\n",
    "# img = cv2.cvtColor(img, cv2.COLOR_BGR2LAB);\n",
    "# l, a, b = cv2.split(img);\n",
    "# clahe = cv2.createCLAHE(clipLimit = 3.0, tileGridSize = (8, 8));\n",
    "# img_l = clahe.apply(l);\n",
    "# img_l = cv2.merge((img_l, a, b));\n",
    "# final = cv2.cvtColor(img_l, cv2.COLOR_LAB2BGR);\n",
    "# final = cv2.cvtColor(final, cv2.COLOR_BGR2RGB);\n",
    "# img = cv2.resize(final, (2048, 2048), interpolation = cv2.INTER_NEAREST)\n",
    "# plt.imsave('/home/uzumochi/eigenjuno/data/test/test3_contrast.png', img)\n",
    "img = mpimg.imread('test1_contrast.png')\n",
    "# img = mpimg.imread('/home/uzumochi/eigenjuno/data/train/small/97.png')\n",
    "img = img[:, :, :3]\n",
    "# split_img = np.empty((64, vec_size))\n",
    "split_img = np.empty((64, vec_size))\n",
    "start_row, end_row, start_col, end_col = 0, 256, 0, 256\n",
    "row_idx = np.array([])\n",
    "NUM = 0\n",
    "for i in range(64):\n",
    "    block = img[start_row : end_row, start_col : end_col]\n",
    "    if end_col != 2048:\n",
    "        start_col += 256\n",
    "        end_col += 256\n",
    "    else:\n",
    "        start_col, end_col = 0, 256\n",
    "        start_row += 256\n",
    "        end_row += 256\n",
    "    split_img[i, :] = np.reshape(block, vec_size)\n",
    "    if np.mean(split_img[i, :]) >= 0.35:\n",
    "        row_idx = np.append(row_idx, i)\n",
    "        NUM += 1\n",
    "    \n",
    "# testing_blocks = split_img[row_idx.astype(int), :]\n",
    "testing_blocks = split_img\n",
    "transform_test = pca_of_data.transform(testing_blocks)\n",
    "split_pred = classifier_svc.predict(transform_test)\n",
    "# split_pred = classifier_svc.predict(testing_blocks)\n",
    "print(split_pred)\n",
    "    \n",
    "fig, axes = plt.subplots(8, 8, figsize = (18, 18));\n",
    "index = 0\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.imshow(split_img[i - 1, :].reshape(256, 256, 3))\n",
    "    if (i - 1) in row_idx:\n",
    "        ax.title.set_text(str(\"{:.2f}\".format(split_pred[index])))\n",
    "        index += 1\n",
    "    ax.axis('off')\n",
    "#         plt.imsave('/home/uzumochi/eigenjuno/data/test/test3_split_512' + str(NUM) + '.png', split_img[i, :].reshape(512, 512, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# print(row_idx)\n",
    "# print(row_idx.astype(int))\n",
    "# testing_blocks = split_img[row_idx.astype(int), :]\n",
    "testing_blocks = split_img\n",
    "# print(testing_blocks.shape)\n",
    "transform_test = pca_of_data.transform(testing_blocks)\n",
    "# print(split_test_pca)\n",
    "# plt.plot(pca_data.explained_variance_ratio_.cumsum());\n",
    "split_pred = classifier_svc.predict(transform_test)\n",
    "# print(split_pred)\n",
    "# for pred in split_pred:\n",
    "#     if pred != 0:\n",
    "#         cv2.rectangle(img, (x1, y1), (x2, y2), (255,0,0), 2)\n",
    "fig, axes = plt.subplots(4, 4, figsize = (18, 18));\n",
    "index = 0\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.imshow(split_img[i - 1, :].reshape(256, 256, 3))\n",
    "    if (i - 1) in row_idx:\n",
    "        ax.title.set_text(str(\"{:.2f}\".format(split_pred[index])))\n",
    "        index += 1\n",
    "    ax.axis('off')\n",
    "# print(split_img)\n",
    "plt.imshow(img)\n",
    "print(split_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd '/home/uzumochi/eigenjuno/data/train/small'\n",
    "\n",
    "vec_size = 512 * 512 * 3;\n",
    "train = np.empty((186, vec_size))\n",
    "for i in range(1, 187):\n",
    "    img = mpimg.imread(str(i) + '.png')\n",
    "    img = img[:, :, :3]\n",
    "    img_1d = np.reshape(img, vec_size)\n",
    "    train[i - 1, :] = img_1d;\n",
    "    \n",
    "tags = genfromtxt('/home/uzumochi/eigenjuno/data/train/tags.csv', delimiter=',')\n",
    "for i in range(186):\n",
    "    if tags[i] == 2:\n",
    "        tags[i] = 1 # sticking to binary classification for now\n",
    "\n",
    "%cd '/home/uzumochi/eigenjuno/data/test'\n",
    "        \n",
    "# img = mpimg.imread('test1_contrast.png')\n",
    "# img = img[:, :, :3]\n",
    "# split_img = np.empty((64, vec_size))\n",
    "# start_row, end_row, start_col, end_col = 0, 256, 0, 256\n",
    "# row_idx = np.array([])\n",
    "# for i in range(64):\n",
    "#     block = img[start_row : end_row, start_col : end_col]\n",
    "#     if end_col != 2048:\n",
    "#         start_col += 256\n",
    "#         end_col += 256\n",
    "#     else:\n",
    "#         start_col, end_col = 0, 256\n",
    "#         start_row += 256\n",
    "#         end_row += 256\n",
    "#     split_img[i, :] = np.reshape(block, vec_size)\n",
    "#     if np.mean(split_img[i, :]) >= 0.35:\n",
    "#         row_idx = np.append(row_idx, i)\n",
    "# x_test = split_img[row_idx.astype(int), :]\n",
    "test = np.empty((9, vec_size))\n",
    "for i in range(10):\n",
    "    img = mpimg.imread('test3_split' + str(i) + '.png')\n",
    "    img = img[:, :, :3]\n",
    "    img_1d = np.reshape(img, vec_size)\n",
    "    test[i - 1, :] = img_1d;\n",
    "\n",
    "pca = PCA().fit(train)\n",
    "train_pca = pca.transform(train)\n",
    "\n",
    "# eigenfaces = pca_x.components_.reshape((x_train.shape[0], 256, 256, 3))\n",
    "\n",
    "test_pca = pca.transform(test)\n",
    "classifier = SVC().fit(train_pca, tags)\n",
    "predictions = classifier.predict(test_pca)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -----------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## contrast images, resize to 256x256, and save\n",
    "*only run me if contrasted images are not already present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# navigate to directory and contrast images using CLAHE\n",
    "%cd '/home/uzumochi/eigenjuno/data/train/cropped'\n",
    "for i in range(1, 281):\n",
    "    img = cv2.imread(str(i) + '.png')\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2LAB);\n",
    "    l, a, b = cv2.split(img);\n",
    "    clahe = cv2.createCLAHE(clipLimit = 3.0, tileGridSize = (8, 8));\n",
    "    img_l = clahe.apply(l);\n",
    "    img_l = cv2.merge((img_l, a, b));\n",
    "    final = cv2.cvtColor(img_l, cv2.COLOR_LAB2BGR);\n",
    "    final = cv2.cvtColor(final, cv2.COLOR_BGR2RGB);\n",
    "    img = cv2.resize(final, (256, 256), interpolation = cv2.INTER_NEAREST)\n",
    "    plt.imsave('/home/uzumochi/eigenjuno/data/train/contrast_256/' + str(i) + '.png', img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# navigate to directory and contrast images using CLAHE\n",
    "%cd '/home/uzumochi/eigenjuno/data/train/cropped'\n",
    "for i in range(1, 281):\n",
    "    img = cv2.imread(str(i) + '.png')\n",
    "#     img = cv2.cvtColor(img, cv2.COLOR_BGR2LAB);\n",
    "#     l, a, b = cv2.split(img);\n",
    "#     clahe = cv2.createCLAHE(clipLimit = 3.0, tileGridSize = (8, 8));\n",
    "#     img_l = clahe.apply(l);\n",
    "#     img_l = cv2.merge((img_l, a, b));\n",
    "#     final = cv2.cvtColor(img_l, cv2.COLOR_LAB2BGR);\n",
    "#     final = cv2.cvtColor(final, cv2.COLOR_BGR2RGB);\n",
    "    img = cv2.resize(img, (256, 256), interpolation = cv2.INTER_NEAREST)\n",
    "    plt.imsave('/home/uzumochi/eigenjuno/data/train/uniform/' + str(i) + '.png', img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pca with uncontrasted data\n",
    "*only keeping for archival purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # read in data\n",
    "# vec_size = 256 * 256 * 3;\n",
    "# train = np.empty((186, vec_size))\n",
    "# for i in range(1, 187):\n",
    "#     img = mpimg.imread(str(i) + '.png')\n",
    "#     img = img[:, :, :3]\n",
    "#     img_1d = np.reshape(img, vec_size)\n",
    "#     train[i - 1, :] = img_1d * 255\n",
    "    \n",
    "# # plot images\n",
    "# fig, axes = plt.subplots(31, 6, figsize = (15, 50));\n",
    "# for i, ax in enumerate(axes.flat):\n",
    "#     ax.imshow(train[i - 1, :].reshape(256, 256, 3) / 255)\n",
    "#     ax.axis('off')\n",
    "# plt.show()\n",
    "\n",
    "# calculate and plot pca\n",
    "pca = PCA().fit(train)\n",
    "plt.figure(figsize = (15, 5))\n",
    "plt.plot(pca.explained_variance_ratio_.cumsum());\n",
    "plt.xlabel('Number of Principal Components')\n",
    "plt.ylabel('Explained Variance Ratio')\n",
    "plt.title('Explained Variance Ratio of Principal Components in a Contrasted Dataset')\n",
    "\n",
    "# transform data with pca\n",
    "data_pca = pca.transform(train)\n",
    "\n",
    "# # transform data with minimum required principal components\n",
    "# pca = PCA(n_components = 6).fit(train)\n",
    "# plt.figure(figsize = (15, 5))\n",
    "# plt.plot(pca.explained_variance_ratio_.cumsum());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## random code \n",
    "visualization, old dev code, or unused"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# visualize results\n",
    "fig, axes = plt.subplots(4, 4, figsize = (15, 15));\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.imshow(x_test[i - 1, :].reshape(256, 256, 3))\n",
    "    ax.title.set_text(str(int(y_test[i - 1])) + \" / \" + str(int(y_pred_SVC[i - 1])))\n",
    "    ax.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot contrasted images\n",
    "fig, axes = plt.subplots(31, 6, figsize = (15, 50));\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.imshow(data[i - 1 , :].reshape(256, 256, 3))\n",
    "    ax.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate and plot contrasted pca\n",
    "pca_x = PCA().fit(x_train)\n",
    "plt.figure(figsize = (15, 5))\n",
    "plt.plot(pca_x.explained_variance_ratio_.cumsum());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform data with contrasted pca\n",
    "x_train_pca = pca_x.transform(x_train)\n",
    "print(np.where(pca_x.explained_variance_ratio_.cumsum() > 0.95));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize first 5 pca components\n",
    "pca_x = PCA(n_components = 6).fit(x_train)\n",
    "plt.figure(figsize = (15, 5))\n",
    "plt.plot(pca_x.explained_variance_ratio_.cumsum());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform data with minimum required contrasted principal components\n",
    "pca_x = PCA(n_components = 75).fit(x_train)\n",
    "plt.figure(figsize = (15, 5))\n",
    "plt.plot(pca_x.explained_variance_ratio_.cumsum());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot eigenfaces\n",
    "fig, axes = plt.subplots(93, 2, figsize = (4, 200));\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.imshow(abs(eigenfaces[i, :]) * 255);\n",
    "    ax.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform data to 2 dimensions\n",
    "x_pca = PCA(2).fit(x_train)\n",
    "x_train_pca = x_pca.transform(x_train)\n",
    "plt.scatter(x_train_pca[:, 0], x_train_pca[:, 1], edgecolor='none', alpha=0.5, cmap=plt.cm.get_cmap('rainbow', 2))\n",
    "plt.xlabel('component 1')\n",
    "plt.ylabel('component 2')\n",
    "plt.colorbar();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inverse transform data\n",
    "x_train_new = x_pca.inverse_transform(x_train_pca)\n",
    "plt.scatter(x_train[:, 0], x_train[:, 1], alpha=0.2)\n",
    "plt.scatter(x_train_new[:, 0], x_train_new[:, 1], alpha=0.8)\n",
    "plt.axis('equal');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original test code for processing new image, unsurprisingly doesnt work well\n",
    "# without chopping up image\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2LAB);\n",
    "l, a, b = cv2.split(img);\n",
    "clahe = cv2.createCLAHE(clipLimit = 3.0, tileGridSize = (8, 8));\n",
    "img_l = clahe.apply(l);\n",
    "img_l = cv2.merge((img_l, a, b));\n",
    "final = cv2.cvtColor(img_l, cv2.COLOR_LAB2BGR);\n",
    "final = cv2.cvtColor(final, cv2.COLOR_BGR2RGB);\n",
    "img = cv2.resize(final, (400, 400), interpolation = cv2.INTER_NEAREST)\n",
    "img_1d = np.reshape(img, vec_size)\n",
    "test_predict = classifier_svc.predict(img_1d)\n",
    "print(test_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some print statements i used in development that i will leave here for now\n",
    "# print('LinearSVC')\n",
    "# print(classification_report(y_test, y_pred_LSVC, target_names = ['No storms', 'Storms']))\n",
    "# print('\\nSVC')\n",
    "# print(classification_report(y_test, y_pred_SVC))\n",
    "# print('\\nMLPClassifier')\n",
    "# print(classification_report(y_test, y_pred_MLP))\n",
    "# print('\\nNearest Neighbor')\n",
    "# print(classification_report(y_test, y_pred_NN))\n",
    "# print('\\nDecision Tree')\n",
    "# print(classification_report(y_test, y_pred_DT))\n",
    "# print('\\nRandom Forest')\n",
    "# print(classification_report(y_test, y_pred_RF))\n",
    "# print('\\nAda Boost')\n",
    "# print(classification_report(y_test, y_pred_AB))\n",
    "# print('\\nNaive Bayes')\n",
    "# print(classification_report(y_test, y_pred_NB))\n",
    "# print('\\nLDA')\n",
    "# print(classification_report(y_test, y_pred_LDA))\n",
    "# print('\\nQDA')\n",
    "# print(classification_report(y_test, y_pred_QDA))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some unused code to isolate images in test set with white storms\n",
    "data_new = np.empty((114, vec_size))\n",
    "tags_new = np.array([])\n",
    "index = 0\n",
    "for i in range(186):\n",
    "    if tags[i] != 1:\n",
    "        tags_new = np.append(tags_new, tags[i])\n",
    "        data_new[index] = data[i, :]\n",
    "        index += 1\n",
    "data = data_new\n",
    "tags = tags_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd '/home/uzumochi/eigenjuno/data/train/uniform'\n",
    "img = mpimg.imread('1.png')\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd '/home/uzumochi/eigenjuno/data/train/contrast'\n",
    "img = mpimg.imread('1.png')\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /home/uzumochi/eigenjuno/data/train\n",
    "tags = genfromtxt('/home/uzumochi/eigenjuno/data/train/tags_old.csv', delimiter = ',')\n",
    "for i in range(186):\n",
    "    if tags[i] == 2:\n",
    "        tags[i] = int(1)\n",
    "np.savetxt('tags.csv', tags.astype(int), delimiter = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
