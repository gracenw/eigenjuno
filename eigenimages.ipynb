{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2, sys, os, random, json\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy import genfromtxt\n",
    "from sklearn.svm import SVC, SVR, LinearSVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## read in training/testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in contrasted data and tags\n",
    "%cd '/home/uzumochi/eigenjuno/data/train/contrast_256'\n",
    "vec_size = 256 * 256 * 3;\n",
    "data = np.empty((78 * 2, vec_size))\n",
    "\n",
    "# ensure dataset class distribution is even\n",
    "storm_indices = []\n",
    "no_storm_indices = []\n",
    "tags = genfromtxt('/home/uzumochi/eigenjuno/data/train/tags.csv', delimiter=',')\n",
    "for t in range(len(tags)):\n",
    "    if tags[t] == 1:\n",
    "        storm_indices.append(t)\n",
    "    else:\n",
    "        no_storm_indices.append(t)\n",
    "selected_imgs = random.sample(storm_indices, 78) + no_storm_indices\n",
    "curr = 0\n",
    "for i in range(1, 281):\n",
    "    if i in selected_imgs:\n",
    "        img = mpimg.imread(str(i) + '.png')\n",
    "        img = img[:, :, :3]\n",
    "        img_1d = np.reshape(img, vec_size)\n",
    "        data[curr, :] = img_1d;\n",
    "        curr += 1\n",
    "tags = [tags[i] for i in selected_imgs]\n",
    "\n",
    "# set loop parameters\n",
    "iterations = 5\n",
    "test_size = 40\n",
    "num_tests = 1\n",
    "accuracy = np.zeros(num_tests)\n",
    "total_predictions = iterations * test_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## display contrasted dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(int(data.shape[0] / 6), 6, figsize = (15, 50));\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.imshow(data[i - 1 , :].reshape(256, 256, 3))\n",
    "    ax.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## perform training w/ pca and eigenimaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(iterations):\n",
    "    # split data into training and test sets\n",
    "    x_train, x_test, y_train, y_test = train_test_split(data, tags, test_size = test_size)\n",
    "\n",
    "    # perform original transform again for classification purposes\n",
    "    pca_x = PCA().fit(x_train)\n",
    "    x_train_pca = pca_x.transform(x_train)\n",
    "\n",
    "    # compute eigenfaces\n",
    "    eigenfaces = pca_x.components_.reshape((x_train.shape[0], 256, 256, 3))\n",
    "\n",
    "    # apply pca transform to x_test\n",
    "    x_test_pca = pca_x.transform(x_test)\n",
    "    classifier_svc = SVC().fit(x_train_pca, y_train)\n",
    "#     classifier_linsvc = LinearSVC().fit(x_train_pca, y_train)\n",
    "#     classifier_mlp = MLPClassifier(activation='logistic').fit(x_train_pca, y_train)\n",
    "#     classifier_nearestneighbor = KNeighborsClassifier(weights = 'distance').fit(x_train_pca, y_train)\n",
    "#     classifier_decisiontree = DecisionTreeClassifier().fit(x_train_pca, y_train)\n",
    "#     classifier_randomforest = RandomForestClassifier().fit(x_train_pca, y_train)\n",
    "#     classifier_adaboost = AdaBoostClassifier().fit(x_train_pca, y_train)\n",
    "#     classifier_naivebayes = GaussianNB().fit(x_train_pca, y_train)\n",
    "#     classifier_lda = LinearDiscriminantAnalysis().fit(x_train_pca, y_train)\n",
    "#     classifier_qda = QuadraticDiscriminantAnalysis().fit(x_train_pca, y_train)\n",
    "    \n",
    "    # generate predictions\n",
    "    y_pred_SVC = classifier_svc.predict(x_test_pca)\n",
    "#     y_pred_LSVC = classifier_linsvc.predict(x_test_pca)\n",
    "#     y_pred_MLP = classifier_mlp.predict(x_test_pca)\n",
    "#     y_pred_NN = classifier_nearestneighbor.predict(x_test_pca)\n",
    "#     y_pred_DT = classifier_decisiontree.predict(x_test_pca)\n",
    "#     y_pred_RF = classifier_randomforest.predict(x_test_pca)\n",
    "#     y_pred_AB = classifier_adaboost.predict(x_test_pca)\n",
    "#     y_pred_NB = classifier_naivebayes.predict(x_test_pca)\n",
    "#     y_pred_LDA = classifier_lda.predict(x_test_pca)\n",
    "#     y_pred_QDA = classifier_qda.predict(x_test_pca)\n",
    "#     predictions = [y_pred_SVC, y_pred_LSVC, y_pred_MLP, y_pred_NN, y_pred_DT, \n",
    "#                    y_pred_RF, y_pred_AB, y_pred_NB, y_pred_LDA, y_pred_QDA]\n",
    "\n",
    "    # log accuracy\n",
    "#     for i in range(num_tests):\n",
    "#         for k in range(test_size):\n",
    "#             if predictions[i][k] == y_test[k]:\n",
    "#                 accuracy[i] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## print results and analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy = accuracy / total_predictions\n",
    "# print('Support Vector Classifier: ' + str(\"{:.3f}\".format(accuracy[0])))\n",
    "print(classification_report(y_test, y_pred_SVC))\n",
    "# print('Linear Support Vector Classifier: ' + str(\"{:.2f}\".format(accuracy[1])))\n",
    "# print(classification_report(y_test, y_pred_LSVC, target_names = ['No storms', 'Storms']))\n",
    "# print('Multilayer Perceptron Classifier: ' + str(\"{:.2f}\".format(accuracy[2])))\n",
    "# print(classification_report(y_test, y_pred_MLP))\n",
    "# print('K-Nearest Neighbor: ' + str(\"{:.2f}\".format(accuracy[3])))\n",
    "# print(classification_report(y_test, y_pred_NN))\n",
    "# print('Decision Tree: ' + str(\"{:.2f}\".format(accuracy[4])))\n",
    "# print(classification_report(y_test, y_pred_DT))\n",
    "# print('Random Forest: ' + str(\"{:.2f}\".format(accuracy[5])))\n",
    "# print(classification_report(y_test, y_pred_RF))\n",
    "# print('Adaptive Boosting: ' + str(\"{:.2f}\".format(accuracy[6])))\n",
    "# print(classification_report(y_test, y_pred_AB))\n",
    "# print('Gaussian Naive Bayes: ' + str(\"{:.2f}\".format(accuracy[7])))\n",
    "# print(classification_report(y_test, y_pred_NB))\n",
    "# print('Linear Discriminant Analysis: ' + str(\"{:.2f}\".format(accuracy[8])))\n",
    "# print(classification_report(y_test, y_pred_LDA))\n",
    "# print('Quadratic Discriminant Analysis: ' + str(\"{:.2f}\".format(accuracy[9])))\n",
    "# print(classification_report(y_test, y_pred_QDA))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot eigenfaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "eigenfaces = (abs(eigenfaces.astype('float32'))).astype('uint8')\n",
    "fig, axes = plt.subplots(4, 6, figsize = (15, 10));\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.imshow(eigenfaces[i, :]);\n",
    "    ax.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## visualize svc results w/ images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(6, 6, figsize = (15, 20));\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.imshow(x_test[i - 1, :].reshape(256, 256, 3))\n",
    "    ax.title.set_text('val: ' + str(int(y_test[i - 1])) + \" / pred: \" + str(int(y_pred_SVC[i - 1])))\n",
    "    ax.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## contrast single test image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = ''\n",
    "img = cv2.imread('/home/uzumochi/eigenjuno/data/test/' + name + '.png')\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2LAB);\n",
    "l, a, b = cv2.split(img);\n",
    "clahe = cv2.createCLAHE(clipLimit = 3.0, tileGridSize = (8, 8));\n",
    "img_l = clahe.apply(l);\n",
    "img_l = cv2.merge((img_l, a, b));\n",
    "final = cv2.cvtColor(img_l, cv2.COLOR_LAB2BGR);\n",
    "final = cv2.cvtColor(final, cv2.COLOR_BGR2RGB);\n",
    "img = cv2.resize(final, (2048, 2048), interpolation = cv2.INTER_NEAREST)\n",
    "plt.imsave('/home/uzumochi/eigenjuno/data/test/' + name + '_contrast.png', img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## divide-and-conquer pipeline for testing full images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd '/home/uzumochi/eigenjuno/data/test'\n",
    "\n",
    "# calculate pca/eigenfaces of full dataset\n",
    "pca_of_data = PCA().fit(data)\n",
    "transform_data = pca_of_data.transform(data)\n",
    "eigenfaces = pca_of_data.components_.reshape((data.shape[0], 256, 256, 3))\n",
    "classifier_svc = SVC().fit(transform_data, tags)\n",
    "\n",
    "# chop up image\n",
    "test_name = 'test3_contrast'\n",
    "vec_size = 256 * 256 * 3\n",
    "test_predict = np.empty(64)\n",
    "img = mpimg.imread(test_name + '.png')\n",
    "img = img[:, :, :3]\n",
    "split_img = np.empty((64, vec_size))\n",
    "start_row, end_row, start_col, end_col = 0, 256, 0, 256\n",
    "row_idx = np.array([])\n",
    "NUM = 0\n",
    "for i in range(64):\n",
    "    block = img[start_row : end_row, start_col : end_col]\n",
    "    if end_col != 2048:\n",
    "        start_col += 256\n",
    "        end_col += 256\n",
    "    else:\n",
    "        start_col, end_col = 0, 256\n",
    "        start_row += 256\n",
    "        end_row += 256\n",
    "    split_img[i, :] = np.reshape(block, vec_size)\n",
    "    if np.mean(split_img[i, :]) >= 0.35:\n",
    "        row_idx = np.append(row_idx, i)\n",
    "        NUM += 1\n",
    "\n",
    "# generate predictions for individual blocks\n",
    "testing_blocks = split_img[row_idx.astype(int), :]\n",
    "transform_test = pca_of_data.transform(testing_blocks)\n",
    "split_pred = classifier_svc.predict(transform_test)\n",
    "\n",
    "# graph results\n",
    "fig, axes = plt.subplots(8, 8, figsize = (18, 18));\n",
    "index = 0\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.imshow(split_img[i - 1, :].reshape(256, 256, 3))\n",
    "    if (i - 1) in row_idx:\n",
    "        ax.title.set_text(str(\"{:.2f}\".format(split_pred[index])))\n",
    "        index += 1\n",
    "    ax.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## contrast images, resize to 256x256, and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd '/home/uzumochi/eigenjuno/data/train/cropped'\n",
    "for i in range(1, 281):\n",
    "    img = cv2.imread(str(i) + '.png')\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2LAB);\n",
    "    l, a, b = cv2.split(img);\n",
    "    clahe = cv2.createCLAHE(clipLimit = 3.0, tileGridSize = (8, 8));\n",
    "    img_l = clahe.apply(l);\n",
    "    img_l = cv2.merge((img_l, a, b));\n",
    "    final = cv2.cvtColor(img_l, cv2.COLOR_LAB2BGR);\n",
    "    final = cv2.cvtColor(final, cv2.COLOR_BGR2RGB);\n",
    "    img = cv2.resize(final, (256, 256), interpolation = cv2.INTER_NEAREST)\n",
    "    plt.imsave('/home/uzumochi/eigenjuno/data/train/contrast_256/' + str(i) + '.png', img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pca with uncontrasted data - minimum components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components = 6).fit(data)\n",
    "plt.figure(figsize = (15, 5));\n",
    "plt.plot(pca.explained_variance_ratio_.cumsum());\n",
    "plt.xlabel('Number of Principal Components');\n",
    "plt.ylabel('Explained Variance Ratio');\n",
    "plt.title('Explained Variance Ratio of Principal Components in a Contrasted Dataset: First 5 Components');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pca with uncontrasted data - all components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA().fit(data)\n",
    "plt.figure(figsize = (15, 5));\n",
    "plt.plot(pca.explained_variance_ratio_.cumsum());\n",
    "plt.xlabel('Number of Principal Components');\n",
    "plt.ylabel('Explained Variance Ratio');\n",
    "plt.title('Explained Variance Ratio of Principal Components in a Contrasted Dataset');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pca scatter plot - first two components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj = PCA().fit_transform(data)\n",
    "plt.scatter(proj[:, 0], proj[:, 1], cmap=plt.cm.get_cmap('rainbow', 2));\n",
    "plt.xlabel('component 1');\n",
    "plt.ylabel('component 2');\n",
    "plt.colorbar();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## read meta data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with f as open(test_name + '.json', 'r'):\n",
    "    data = json.load(f)\n",
    "    solar_distance = data['SOLAR_DISTANCE']\n",
    "    craft_altitude = data['SPACECRAFT_ALTITUDE']\n",
    "    sub_latitude = data['SUB_SPACECRAFT_LATITUDE']\n",
    "    sub_longitude = data['SUB_SPACECRAFT_LONGITUDE']\n",
    "    \n",
    "# find lat/long of center of identified image\n",
    "# zoom in/out to focus on desired feature\n",
    "# track features with centerpoint\n",
    "# save in log file w/ coordinates, perijove, and feature id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# end of notebook"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
