{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2, sys, os, random, json, math\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy import genfromtxt\n",
    "from sklearn.svm import SVC, NuSVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import classification_report\n",
    "from stitching.stitch import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## read in training/testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd '/home/uzumochi/eigenjuno/data/train/contrast'\n",
    "\n",
    "# read in contrasted data and tags\n",
    "tags = genfromtxt('/home/uzumochi/eigenjuno/data/train/tags.csv', delimiter=',')\n",
    "vec_size = 256 * 256 * 3;\n",
    "\n",
    "# ensure dataset class distribution is even\n",
    "storm_indices = []\n",
    "no_storm_indices = []\n",
    "\n",
    "for t in range(350):\n",
    "    if tags[t] == 1:\n",
    "        storm_indices.append(t)\n",
    "    else:\n",
    "        no_storm_indices.append(t)\n",
    "\n",
    "number_zeros = int(len(no_storm_indices) / 2)\n",
    "\n",
    "selected_indices = np.append(random.sample(storm_indices, number_zeros), no_storm_indices)\n",
    "\n",
    "selected_tags = []\n",
    "\n",
    "selected_imgs = np.empty((len(selected_indices), vec_size))\n",
    "\n",
    "curr = 0\n",
    "for i in selected_indices:\n",
    "    img = mpimg.imread(str(i + 1) + '.png')\n",
    "    img = img[:, :, :3]\n",
    "    img_1d = np.reshape(img, vec_size)\n",
    "    selected_imgs[curr, :] = img_1d;\n",
    "    selected_tags = np.append(selected_tags, tags[i])\n",
    "    curr += 1\n",
    "    \n",
    "# tags = np.append(selected_tags, np.full(10, -1)) # int(number_zeros / 4)\n",
    "# data = np.append(selected_imgs, np.full((10, vec_size), 0), axis = 0)\n",
    "\n",
    "tags = selected_tags\n",
    "data = selected_imgs\n",
    "\n",
    "# set loop parameters\n",
    "iterations = 1\n",
    "test_size = 40"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## display contrasted dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(int(data.shape[0] / 11), 11, figsize = (15, 100));\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.imshow(data[i, :].reshape(256, 256, 3))\n",
    "    ax.title.set_text(str(int(tags[i])))\n",
    "    ax.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## perform training w/ pca and eigenimaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(iterations):\n",
    "    # split data into training and test sets\n",
    "    x_train, x_test, y_train, y_test = train_test_split(data, tags, test_size = test_size)\n",
    "\n",
    "    # perform original transform again for classification purposes\n",
    "    pca_x = PCA().fit(x_train)\n",
    "    x_train_pca = pca_x.transform(x_train)\n",
    "\n",
    "    # compute eigenfaces\n",
    "    eigenfaces = pca_x.components_.reshape((x_train.shape[0], 256, 256, 3))\n",
    "\n",
    "    # apply pca transform to x_test\n",
    "    x_test_pca = pca_x.transform(x_test)\n",
    "    \n",
    "    # fit classifier to data\n",
    "    classifier_svc = SVC().fit(x_train_pca, y_train)\n",
    "    classifier_mlp = MLPClassifier(activation = 'logistic').fit(x_train_pca, y_train)\n",
    "    classifier_nn = KNeighborsClassifier(weights = 'distance').fit(x_train_pca, y_train)\n",
    "    classifier_nus = NuSVC().fit(x_train_pca, y_train)\n",
    "    \n",
    "    # generate predictions\n",
    "    y_pred_SVC = classifier_svc.predict(x_test_pca)\n",
    "    y_pred_MLP = classifier_mlp.predict(x_test_pca)\n",
    "    y_pred_NN = classifier_nn.predict(x_test_pca)\n",
    "    y_pred_NUS = classifier_nus.predict(x_test_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## print results and analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred_SVC))\n",
    "print(classification_report(y_test, y_pred_MLP))\n",
    "print(classification_report(y_test, y_pred_NN))\n",
    "print(classification_report(y_test, y_pred_NUS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot eigenfaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigenfaces = (abs(eigenfaces.astype('float32'))).astype('uint8')\n",
    "fig, axes = plt.subplots(4, 6, figsize = (15, 10));\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.imshow(eigenfaces[i, :]);\n",
    "    ax.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## visualize results w/ images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(6, 6, figsize = (15, 20));\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.imshow(x_test[i - 1, :].reshape(256, 256, 3))\n",
    "    ax.title.set_text('val: ' + str(int(y_test[i - 1])) + \" / pred: \" + str(int(y_pred_SVC[i - 1])))\n",
    "    ax.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## contrast single test image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'test2'\n",
    "img = cv2.imread('/home/uzumochi/eigenjuno/data/test/' + name + '.png')\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2LAB);\n",
    "l, a, b = cv2.split(img);\n",
    "clahe = cv2.createCLAHE(clipLimit = 3.0, tileGridSize = (8, 8));\n",
    "img_l = clahe.apply(l);\n",
    "img_l = cv2.merge((img_l, a, b));\n",
    "final = cv2.cvtColor(img_l, cv2.COLOR_LAB2BGR);\n",
    "final = cv2.cvtColor(final, cv2.COLOR_BGR2RGB);\n",
    "img = cv2.resize(final, (2048, 2048), interpolation = cv2.INTER_NEAREST)\n",
    "plt.imsave('/home/uzumochi/eigenjuno/data/test/' + name + '_contrast.png', img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## divide-and-conquer pipeline for testing full images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%cd '/home/uzumochi/eigenjuno/data/test'\n",
    "\n",
    "# chop up image\n",
    "test_name = 'test2_contrast'\n",
    "vec_size = 256 * 256 * 3\n",
    "img = cv2.imread(test_name + '.png', 3)\n",
    "b, g, r = cv2.split(img)\n",
    "img = cv2.merge((r, g, b))\n",
    "img = (img / 255)\n",
    "split_img_4 = np.empty((4, vec_size))\n",
    "split_img_16 = np.empty((16, vec_size))\n",
    "split_img_64 = np.empty((64, vec_size))\n",
    "split_img_256 = np.empty((256, vec_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "############### 128X128 RESOLUTION BLOCKS ################\n",
    "start_row, end_row, start_col, end_col = 0, 128, 0, 128\n",
    "non_zero_blocks = []\n",
    "index = 0\n",
    "for i in range(256):\n",
    "    block = img[start_row : end_row, start_col : end_col]\n",
    "    if end_col != 2048:\n",
    "        start_col += 128\n",
    "        end_col += 128\n",
    "    else:\n",
    "        start_col, end_col = 0, 128\n",
    "        start_row += 128\n",
    "        end_row += 128\n",
    "    block = cv2.resize(block, (256, 256), interpolation = cv2.INTER_NEAREST)\n",
    "    block = np.reshape(block, vec_size)\n",
    "    split_img_256[i, :] = block\n",
    "    zero_locs = np.where(block < 0.025)[0]\n",
    "    if zero_locs.size == 0:\n",
    "        index += 1\n",
    "        non_zero_blocks = np.append(non_zero_blocks, i)\n",
    "\n",
    "# generate predictions for individual blocks\n",
    "testing_blocks = split_img_256[non_zero_blocks.astype(int), :]\n",
    "transform_test_256 = pca_x.transform(testing_blocks)\n",
    "split_pred_256 = classifier_nus.predict(transform_test_256)\n",
    "\n",
    "# graph results\n",
    "fig, axes = plt.subplots(16, 16, figsize = (18, 24));\n",
    "index = 0\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.imshow(split_img_256[i, :].reshape(256, 256, 3))\n",
    "    if i in non_zero_blocks:\n",
    "        ax.title.set_text(str(float(split_pred_256[index])))\n",
    "        index += 1\n",
    "    ax.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############### 256X256 RESOLUTION BLOCKS ################\n",
    "start_row, end_row, start_col, end_col = 0, 256, 0, 256\n",
    "non_zero_blocks = []\n",
    "index = 0\n",
    "for i in range(64):\n",
    "    block = img[start_row : end_row, start_col : end_col]\n",
    "    if end_col != 2048:\n",
    "        start_col += 256\n",
    "        end_col += 256\n",
    "    else:\n",
    "        start_col, end_col = 0, 256\n",
    "        start_row += 256\n",
    "        end_row += 256\n",
    "    block = np.reshape(block, vec_size)\n",
    "    split_img_64[i, :] = block\n",
    "    zero_locs = np.where(block < 0.025)[0]\n",
    "    if zero_locs.size == 0:\n",
    "        index += 1\n",
    "        non_zero_blocks = np.append(non_zero_blocks, i)\n",
    "\n",
    "# generate predictions for individual blocks\n",
    "testing_blocks = split_img_64[non_zero_blocks.astype(int), :]\n",
    "transform_test_64 = pca_x.transform(testing_blocks)\n",
    "split_pred_64 = classifier_mlp.predict(transform_test_64)\n",
    "\n",
    "# graph results\n",
    "fig, axes = plt.subplots(8, 8, figsize = (18, 18));\n",
    "index = 0\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.imshow(split_img_64[i, :].reshape(256, 256, 3))\n",
    "    if i in non_zero_blocks:\n",
    "        ax.title.set_text(str(float(split_pred_64[index])))\n",
    "        index += 1\n",
    "    ax.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############### 512X512 RESOLUTION BLOCKS ################\n",
    "start_row, end_row, start_col, end_col = 0, 512, 0, 512\n",
    "non_zero_blocks = []\n",
    "index = 0\n",
    "for i in range(16):\n",
    "    block = img[start_row : end_row, start_col : end_col]\n",
    "    if end_col != 2048:\n",
    "        start_col += 512\n",
    "        end_col += 512\n",
    "    else:\n",
    "        start_col, end_col = 0, 512\n",
    "        start_row += 512\n",
    "        end_row += 512\n",
    "    block = cv2.resize(block, (256, 256))\n",
    "    block = np.reshape(block, vec_size)\n",
    "    split_img_16[i, :] = block\n",
    "    zero_locs = np.where(block < 0.025)[0]\n",
    "    if zero_locs.size == 0:\n",
    "        index += 1\n",
    "        non_zero_blocks = np.append(non_zero_blocks, i)\n",
    "\n",
    "# generate predictions for individual blocks\n",
    "testing_blocks = split_img_16[non_zero_blocks.astype(int), :]\n",
    "transform_test_16 = pca_x.transform(testing_blocks)\n",
    "split_pred_16 = classifier_nn.predict(transform_test_16)\n",
    "\n",
    "# graph results\n",
    "fig, axes = plt.subplots(4, 4, figsize = (18, 18));\n",
    "index = 0\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.imshow(split_img_16[i, :].reshape(256, 256, 3))\n",
    "    if i in non_zero_blocks:\n",
    "        ax.title.set_text(str(float(split_pred_16[index])))\n",
    "        index += 1\n",
    "    ax.axis('off')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############### 1024X1024 RESOLUTION BLOCKS ################\n",
    "start_row, end_row, start_col, end_col = 0, 1024, 0, 1024\n",
    "non_zero_blocks = []\n",
    "index = 0\n",
    "for i in range(4):\n",
    "    block = img[start_row : end_row, start_col : end_col]\n",
    "    if end_col != 2048:\n",
    "        start_col += 1024\n",
    "        end_col += 1024\n",
    "    else:\n",
    "        start_col, end_col = 0, 1024\n",
    "        start_row += 1024\n",
    "        end_row += 1024\n",
    "    block = cv2.resize(block, (256, 256))\n",
    "    block = np.reshape(block, vec_size)\n",
    "    split_img_4[i, :] = block\n",
    "    zero_locs = np.where(block < 0.025)[0]\n",
    "    if zero_locs.size == 0:\n",
    "        index += 1\n",
    "        non_zero_blocks = np.append(non_zero_blocks, i)\n",
    "\n",
    "# generate predictions for individual blocks\n",
    "testing_blocks = split_img_4[non_zero_blocks.astype(int), :]\n",
    "transform_test_4 = pca_x.transform(testing_blocks)\n",
    "split_pred_4 = classifier_nn.predict(transform_test_4)\n",
    "\n",
    "# graph results\n",
    "fig, axes = plt.subplots(2, 2, figsize = (18, 18));\n",
    "index = 0\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.imshow(split_img_4[i, :].reshape(256, 256, 3))\n",
    "    if i in non_zero_blocks:\n",
    "        ax.title.set_text(str(float(split_pred_4[index])))\n",
    "        index += 1\n",
    "    ax.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## contrast images, resize to 256x256, and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd '/home/uzumochi/eigenjuno/data/train/cropped'\n",
    "for i in range(281, 376):\n",
    "    img = cv2.imread(str(i) + '.png')\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2LAB);\n",
    "    l, a, b = cv2.split(img);\n",
    "    clahe = cv2.createCLAHE(clipLimit = 3.0, tileGridSize = (8, 8));\n",
    "    img_l = clahe.apply(l);\n",
    "    img_l = cv2.merge((img_l, a, b));\n",
    "    final = cv2.cvtColor(img_l, cv2.COLOR_LAB2BGR);\n",
    "    final = cv2.cvtColor(final, cv2.COLOR_BGR2RGB);\n",
    "    img = cv2.resize(final, (256, 256), interpolation = cv2.INTER_NEAREST)\n",
    "    plt.imsave('/home/uzumochi/eigenjuno/data/train/contrast/' + str(i) + '.png', img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pca with uncontrasted data - minimum components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components = 6).fit(data)\n",
    "plt.figure(figsize = (15, 5));\n",
    "plt.plot(pca.explained_variance_ratio_.cumsum());\n",
    "plt.xlabel('Number of Principal Components');\n",
    "plt.ylabel('Explained Variance Ratio');\n",
    "plt.title('Explained Variance Ratio of Principal Components in a Contrasted Dataset: First 5 Components');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pca with uncontrasted data - all components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA().fit(data)\n",
    "plt.figure(figsize = (15, 5));\n",
    "plt.plot(pca.explained_variance_ratio_.cumsum());\n",
    "plt.xlabel('Number of Principal Components');\n",
    "plt.ylabel('Explained Variance Ratio');\n",
    "plt.title('Explained Variance Ratio of Principal Components in a Contrasted Dataset');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pca scatter plot - first two components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj = PCA().fit_transform(data)\n",
    "plt.scatter(proj[:, 0], proj[:, 1], cmap=plt.cm.get_cmap('rainbow', 2));\n",
    "plt.xlabel('component 1');\n",
    "plt.ylabel('component 2');\n",
    "plt.colorbar();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## useful functions for spice matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert rotational matrix to euler angles\n",
    "def rot_matrix_to_euler(R) :\n",
    "    sy = math.sqrt(R[0,0] * R[0,0] +  R[1,0] * R[1,0])\n",
    "    singular = sy < 1e-6\n",
    "    if  not singular :\n",
    "        x = math.atan2(R[2,1] , R[2,2])\n",
    "        y = math.atan2(-R[2,0], sy)\n",
    "        z = math.atan2(R[1,0], R[0,0])\n",
    "    else :\n",
    "        x = math.atan2(-R[1,2], R[1,1])\n",
    "        y = math.atan2(-R[2,0], sy)\n",
    "        z = 0\n",
    "    return np.array([x, y, z])\n",
    "\n",
    "# convert euler angles in radians to degrees\n",
    "def radians_to_degrees(R):\n",
    "    x = math.degrees(R[0])\n",
    "    y = math.degrees(R[1])\n",
    "    z = math.degrees(R[2])\n",
    "    return np.array([x, y, z])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## read test image metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, math\n",
    "import numpy as np\n",
    "import spiceypy as spice\n",
    "\n",
    "path = '/home/uzumochi/eigenjuno/stitching/kernels/'\n",
    "KERNEL_LIST = [ path+\"naif0012.tls\", path+\"de430.bsp\", path+\"juno_v12.tf\", \n",
    "                path+\"jup310.bsp\", path+\"jno_sclkscet_00094.tsc\", path+\"perijove_9.bsp\", \n",
    "                path+\"pck00010.tpc\", path+\"perijove_9.bc\", path+\"juno_junocam_v02.ti\" ]\n",
    "spice.kclear\n",
    "spice.furnsh(KERNEL_LIST)\n",
    "\n",
    "JUNO_JUNOCAM = -61500\n",
    "JUNO_JUNOCAM_BLUE = -61501\n",
    "JUNO_JUNOCAM_GREEN = -61502\n",
    "JUNO_JUNOCAM_RED = -61503\n",
    "\n",
    "with open('/home/uzumochi/eigenjuno/data/test/test2_contrast.json', 'r') as f:\n",
    "    im_info_dir = json.load(f)\n",
    "    image = im_info_dir['FILE_NAME']\n",
    "    image_time = im_info_dir['START_TIME']\n",
    "    juno_pos = [float(im_info_dir['SUB_SPACECRAFT_LATITUDE']), \n",
    "                float(im_info_dir['SUB_SPACECRAFT_LONGITUDE'])]\n",
    "et = spice.str2et(image_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## find lat/long of image centerpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sun_pos = get_sun_jupiter_rel_pos(image_time)\n",
    "# cam_pos, cam_orient = get_junocam_jupiter_rel_pos_orient(image_time)\n",
    "# orient_angles = rot_matrix_to_euler(orient)\n",
    "# orient_angles = radians_to_degrees(orient_angles)\n",
    "\n",
    "# print('juno subspacecraft lat/long (degrees): ', juno_pos)\n",
    "# print('sun position relative to jupiter (km): ', sun_pos)\n",
    "# print('junocam position relative to jupiter (km): ', pos)\n",
    "# print('junocam orient angles (degrees): ', orient_angles)\n",
    "\n",
    "# proj_points, ray_mask = project_onto_jupiter_surf(pos, orient)\n",
    "# proj_points = proj_points[ray_mask, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Calculate the rotation offset between J2000 and IAU_JUPITER\n",
    "# rot_matrix = spice.pxform('J2000', 'IAU_JUPITER', et)\n",
    "# rot_angles = rot_matrix_to_euler(rot_matrix)\n",
    "# J2000_IAU = radians_to_degrees(rot_angles)\n",
    "\n",
    "# # Get the rotation of JUNO_SPACECRAFT relative to the IAU_JUPITER frame\n",
    "# rot_matrix = spice.pxform('IAU_JUPITER', 'JUNO_SPACECRAFT', et)\n",
    "# rot_angles = rot_matrix_to_euler(rot_matrix)\n",
    "# IAU_JUNO = radians_to_degrees(rot_angles)\n",
    "\n",
    "# # Get the rotation of the JUNO_JUNOCAM_CUBE to the SPACECRAFT, based upon data in juno_v12.tf\n",
    "# rot_matrix = np.matrix([[-0.0059163, -0.0142817, -0.9998805], \n",
    "#                         [0.0023828, -0.9998954,  0.0142678], \n",
    "#                         [-0.9999797, -0.0022981,  0.0059497]])\n",
    "# rot_angles = rot_matrix_to_euler(rot_matrix)\n",
    "# JUNO_CUBE = radians_to_degrees(rot_angles)\n",
    "\n",
    "# # Get the rotation of JUNO_JUNOCAM to JUNO_JUNOCAM_CUBE, based upon data in juno_v12.tf\n",
    "# CUBE_CAM = [0.583, -0.469, 0.69]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-10-24T17:14:31.212\n"
     ]
    },
    {
     "ename": "NotFoundError",
     "evalue": "Spice returns not found for function: sincpt",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "Input \u001b[0;32mIn [13]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# _, frame, bsight, n, bounds = spice.getfov(JUNO_JUNOCAM_BLUE, 4, 32, 32)\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# spoint_b, trgepc, srfvec = spice.sincpt(\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m#     'Ellipsoid', 'JUPITER', et, 'IAU_JUPITER', 'CN+S', 'JUNO_SPACECRAFT', frame, bsight)\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# _, long_b, lat_b = spice.reclat(spoint_b)\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# lat_b = math.degrees(lat_b)\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# long_b = math.degrees(long_b)\u001b[39;00m\n\u001b[1;32m     10\u001b[0m _, frame, bsight, n, bounds \u001b[38;5;241m=\u001b[39m spice\u001b[38;5;241m.\u001b[39mgetfov(JUNO_JUNOCAM_GREEN, \u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m32\u001b[39m, \u001b[38;5;241m32\u001b[39m)\n\u001b[0;32m---> 11\u001b[0m spoint_g, trgepc, srfvec \u001b[38;5;241m=\u001b[39m \u001b[43mspice\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msincpt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mEllipsoid\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mJUPITER\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43met\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mIAU_JUPITER_400KM\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mCN+S\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mJUNO_SPACECRAFT\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbsight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m _, long_g, lat_g \u001b[38;5;241m=\u001b[39m spice\u001b[38;5;241m.\u001b[39mreclat(spoint_g)\n\u001b[1;32m     14\u001b[0m lat_g \u001b[38;5;241m=\u001b[39m math\u001b[38;5;241m.\u001b[39mdegrees(lat_g)\n",
      "File \u001b[0;32m~/anaconda3/envs/spice/lib/python3.8/site-packages/spiceypy/spiceypy.py:123\u001b[0m, in \u001b[0;36mspice_error_check.<locals>.with_errcheck\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(f)\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwith_errcheck\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    122\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 123\u001b[0m         res \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    124\u001b[0m         check_for_spice_error(f)\n\u001b[1;32m    125\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "File \u001b[0;32m~/anaconda3/envs/spice/lib/python3.8/site-packages/spiceypy/spiceypy.py:143\u001b[0m, in \u001b[0;36mspice_found_exception_thrower.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    141\u001b[0m found \u001b[38;5;241m=\u001b[39m res[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(found, \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m found:\n\u001b[0;32m--> 143\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m stypes\u001b[38;5;241m.\u001b[39mNotFoundError(\n\u001b[1;32m    144\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSpice returns not found for function: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(f\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m),\n\u001b[1;32m    145\u001b[0m         found\u001b[38;5;241m=\u001b[39mfound,\n\u001b[1;32m    146\u001b[0m     )\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m stypes\u001b[38;5;241m.\u001b[39mis_iterable(found) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mall\u001b[39m(found):\n\u001b[1;32m    148\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m stypes\u001b[38;5;241m.\u001b[39mNotFoundError(\n\u001b[1;32m    149\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSpice returns not found in a series of calls for function: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    150\u001b[0m             f\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\n\u001b[1;32m    151\u001b[0m         ),\n\u001b[1;32m    152\u001b[0m         found\u001b[38;5;241m=\u001b[39mfound,\n\u001b[1;32m    153\u001b[0m     )\n",
      "\u001b[0;31mNotFoundError\u001b[0m: Spice returns not found for function: sincpt"
     ]
    }
   ],
   "source": [
    "print(image_time)\n",
    "\n",
    "# _, frame, bsight, n, bounds = spice.getfov(JUNO_JUNOCAM_BLUE, 4, 32, 32)\n",
    "# spoint_b, trgepc, srfvec = spice.sincpt(\n",
    "#     'Ellipsoid', 'JUPITER', et, 'IAU_JUPITER', 'CN+S', 'JUNO_SPACECRAFT', frame, bsight)\n",
    "# _, long_b, lat_b = spice.reclat(spoint_b)\n",
    "# lat_b = math.degrees(lat_b)\n",
    "# long_b = math.degrees(long_b)\n",
    "\n",
    "_, frame, bsight, n, bounds = spice.getfov(JUNO_JUNOCAM_GREEN, 4, 32, 32)\n",
    "spoint_g, trgepc, srfvec = spice.sincpt(\n",
    "    'Ellipsoid', 'JUPITER', et, 'IAU_JUPITER', 'CN+S', 'JUNO_SPACECRAFT', frame, bsight)\n",
    "_, long_g, lat_g = spice.reclat(spoint_g)\n",
    "lat_g = math.degrees(lat_g)\n",
    "long_g = math.degrees(long_g)\n",
    "\n",
    "# _, frame, bsight, n, bounds = spice.getfov(JUNO_JUNOCAM_RED, 4, 32, 32)\n",
    "# spoint_r, trgepc, srfvec = spice.sincpt(\n",
    "#     'Ellipsoid', 'JUPITER', et, 'IAU_JUPITER', 'CN+S', 'JUNO_SPACECRAFT', frame, bsight)\n",
    "# _, long_r, lat_r = spice.reclat(spoint_r)\n",
    "# lat_r = math.degrees(lat_r)\n",
    "# long_r = math.degrees(long_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zoom in/out to focus on desired feature\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# track features with centerpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save in log file w/ coordinates, perijove, and feature id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# end of notebook"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
